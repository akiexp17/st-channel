# RoboPaint: 人間のデモからロボットデータを「描く」

> [!info] 引用元
> [arXiv:2602.05325](https://arxiv.org/abs/2602.05325)

# 概要
ロボットの巧緻な操作（Dexterous Manipulation）を学習させるには大量のデータが必要だが、遠隔操作による収集はコストが高い。「RoboPaint」は、人間の手の動きを動画から抽出し、それをロボットハンドの動きに変換（リターゲット）してシミュレーター内で実行・再撮影することで、ロボット用の学習データを生成するパイプラインである。

# 詳細
- **Real-Sim-Real**: 人間の実演動画（Real）→ シミュレーションでのロボット動作生成（Sim）→ 実機でのポリシー適用（Real）という流れ。
- **Tactile-Aware**: 指先の接触や力を考慮した幾何学的最適化を行うことで、単なる真似ではなく物理的に整合性の取れた動作データを生成。
- **成果**: 生成されたデータのみで学習したVLA（Vision-Language-Action）モデルが、実機でのピック＆プレースや注ぎ動作などで80%の平均成功率を達成。
- **インパクト**: ロボット学習における「データ不足」の壁を、人間の行動データを活用することで突破する有望な手法。
