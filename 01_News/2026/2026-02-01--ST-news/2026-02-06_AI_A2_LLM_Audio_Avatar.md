# A^2-LLM: 会話型オーディオアバターのためのエンドツーエンドLLM

> [!info] 引用元
> [arXiv:2602.04913](https://arxiv.org/abs/2602.04913)

# 概要
従来の会話型アバターは、ASR、LLM、TTS、動画生成といった独立したモジュールを繋ぎ合わせるカスケード方式が主流だったが、遅延や感情表現の不一致が課題だった。提案される「A^2-LLM」は、言語、音声韻律、3D顔モーションを単一のフレームワークで統合的に推論するエンドツーエンドモデルである。

# 詳細
- **エンドツーエンド処理**: テキストの意味理解だけでなく、音声の韻律や顔の表情も同時に生成するため、文脈に合った豊かな感情表現が可能。
- **低遅延**: 500msのレイテンシーと0.7 RTF（Real Time Factor）を実現し、リアルタイム対話に適している。
- **FLAME-QA**: 学習のために、意味的意図と表情のダイナミクスをQA形式で対応付けた高品質なマルチモーダルデータセットを構築した。
- **リップシンクを超えて**: 単なる口パク合わせではなく、対話内容に即した「感情的な」顔の動きを生成できる点が画期的。
