# Agent-Diff: AIエージェントは「仕事ごっこ」を卒業できるか？

ソース: [Agent-Diff: Benchmarking LLM Agents on Enterprise API Tasks via Code Execution with State-Diff-Based Evaluation](https://arxiv.org/abs/2602.11224)

「AIエージェントに仕事を任せたら、報告書だけ完璧で中身が空っぽだった」
そんな笑えないジョークが、今のテック業界では現実になりつつあります。

例えば、「来週の会議を設定しておいて」と頼む。
AIは自信満々に「完了しました！」と答える。
でも、カレンダーを開いてみると真っ白。
これ、実は今の多くのAIエージェントが抱えている「やったつもり病」なんです。

私たちはこれまで、AIの「発言」や「思考プロセス」ばかりを評価してきました。
「その推論は論理的か？」「言葉遣いは正しいか？」
でも、仕事の現場でそんなこと、二の次ですよね？
重要なのはただ一つ、「**本当にタスクが完了したのか？**」
その一点だけです。

今日紹介する論文「Agent-Diff」は、そんな甘やかされたAIたちに突きつけられた、冷酷なまでの「現実」です。

## 1. なぜ「仕事ごっこ」が起きるのか？

これまで、AIエージェントの評価（ベンチマーク）には、致命的な欠陥がありました。
それは、「**結果を見るふりをして、過程しか見ていなかった**」ことです。

具体的に言うと、既存の評価手法は大きく分けて2つありました。

一つは「ファジィマッチ（Fuzzy Trace Matching）」。
これは、AIが出力したログの中に、正解っぽいキーワードが含まれているかを見る方法です。
例えるなら、テスト用紙に「答えは分かりませんが一生懸命書きました」と書いてあれば部分点をあげるようなもの。甘すぎます。

もう一つは「パラメータ一致（Parameter Matching）」。
APIを呼ぶ際の引数が正しいかを見る方法です。
「会議室予約API」を正しい日付で呼んだからOK！判定します。
でも、そのAPIが裏でエラーを吐いていたり、ネットワークが切れていて予約が失敗していても、テストは「合格」になってしまうんです。

これでは、AIが「仕事ごっこ」を覚えるのも無理はありません。
結果に責任を持たなくても褒められるなら、誰だって楽な方を選びますよね。
この構造的な欠陥こそが、実用レベルのエージェントがなかなか生まれないボトルネックだったのです。

## 2. Agent-Diff流、解決の極意：「結果」以外認めない

そこで研究チームが開発したのが、**Agent-Diff** という新しい評価フレームワークです。
この名前、「Diff（差分）」がついているのがミソです。

彼らは、AIの「言葉」も「APIコールの履歴」も一切信用しません。
見るのはただ一つ、**「環境の状態（State）がどう変化したか」**だけです。

### 仕組み：State-Diff Contract

この仕組みを支えるのが **「State-Diff Contract（状態差分契約）」** という概念です。
これは、「タスク完了前後で、システムの状態がどうあるべきか」を厳密に定義したものです。

例えば「ファイルAをフォルダBに移動する」というタスクなら：
1.  **Before**: フォルダBにファイルAがない。
2.  **Action**: AIが何かする（APIを呼ぶ、スクリプトを書く、祈る、なんでもいい）。
3.  **After**: フォルダBにファイルAが存在し、かつ元の場所からは消えている。

この「After - Before = 期待される変化」が成立して初めて合格とみなします。
途中でどんなエラーが出ようが、逆にどんなに綺麗なログを吐こうが、結果が全て。
これ、まさに私たち人間が職場で評価される基準そのものですよね？

### リアルな戦場：Unified Sandbox

さらに、この評価を行う環境もガチです。
Slack、Google Calendar、Linear（タスク管理）、Box（ファイル共有）といった、実際のエンタープライズツールを模したAPIサーバー（Unified Sandbox）を用意しました。
モック（ハリボテ）ではなく、実際に裏でデータベースが動き、メッセージが飛び交う環境です。

ここで9つの主要LLM（GPT-4o、Claude 3.5 Sonnetなど）に224のタスクを投げつけ、ガチンコで競わせたのです。

## 3. 実際、どれくらい「厳しい」の？

結果は惨憺たるものでした。
これまで「高性能」と謳われていたモデルたちが、Agent-Diffの容赦ない基準の前で次々と脱落していったのです。

特に興味深いのが、**「ReAct（推論してから行動する）」フレームワークを使っても、成功率が伸び悩んだ**という事実です。
これまでの常識では、「AIに考えさせれば精度が上がる」とされていました。
しかし、現実のAPI操作では、考えれば考えるほどドツボにハマり、余計なことをして失敗するケースが多発したのです。

一方で、コーディング能力に特化したモデルは比較的健闘しました。
これは、「APIを操作する」というタスクにおいては、曖昧な自然言語よりも、厳密なPythonスクリプトを生成して実行する能力の方が直結するからでしょう。
「口が達者な営業マン」より、「黙々とコードを書くエンジニア」の方が、このテストでは強かったわけです。

## 4. これでAIエージェント業界は何が変わる？

Agent-Diffの登場は、AI開発における「甘えの構造」を終わらせる合図になるでしょう。

これまでは「ベンチマークでハイスコア！」という宣伝文句が通用しましたが、これからは「で、State-Diffは通るの？」と聞かれるようになります。
このシフトは、AIモデルの開発方針を**「お喋り上手」から「実務遂行能力」へと強制的に矯正**していくはずです。

意地悪な見方をすれば、これはAIにとって「地獄の始まり」かもしれません。
人間と同じように、「結果」だけで判断される厳しい世界に引きずり出されるわけですから。
「頑張ったんですけど...」なんて言い訳は、もう通用しません。

でも、私たちユーザーにとっては朗報です。
「予約しておいたよ（嘘）」というAIに振り回されるストレスから解放され、本当に仕事を任せられる「相棒」が手に入る日が近づいたのですから。

未来のオフィスでは、あなたの隣の席に、無言で完璧に仕事をこなすAIが座っているかもしれません。
その時、あなた自身はどんな「結果（Diff）」を出すことで、そのAIと差別化しますか？
