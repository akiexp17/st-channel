# 2026-02-06 Ranked News Candidates

- Source inbox: `2026-02-06_RSS_Links.md`
- Total parsed items: 1231
- Deduplicated items: 1231
- Selected items (top 8, min score 5.2): 8

## Scoring rubric
- Total = 0.35*技術新規性 + 0.30*実務影響 + 0.20*信頼性 + 0.15*鮮度
- Each axis is scored on a 0-10 scale

## Top Candidates

### 1. OpenAI launches new agentic coding model only minutes after Anthropic drops its own
- URL: https://techcrunch.com/2026/02/05/openai-launches-new-agentic-coding-model-only-minutes-after-anthropic-drops-its-own/
- Source: TechCrunch
- Score: 6.59 (新規性 7.0 / 実務影響 4.8 / 信頼性 6.0 / 鮮度 10.0)

### 2. Anthropic releases Opus 4.6 with new ‘agent teams’
- URL: https://techcrunch.com/2026/02/05/anthropic-releases-opus-4-6-with-new-agent-teams/
- Source: TechCrunch
- Score: 6.59 (新規性 7.0 / 実務影響 4.8 / 信頼性 6.0 / 鮮度 10.0)

### 3. IndustryShapes: An RGB-D Benchmark dataset for 6D object pose estimation of industrial assembly components and tools
- URL: https://arxiv.org/abs/2602.05555
- Source: cs.RO updates on arXiv.org
- Score: 6.50 (新規性 5.4 / 実務影響 7.2 / 信頼性 7.0 / 鮮度 7.0)

### 4. Sapiom raises $15M to help AI agents buy their own tech tools
- URL: https://techcrunch.com/2026/02/05/sapiom-raises-15m-to-help-ai-agents-buy-their-own-tech-tools/
- Source: TechCrunch
- Score: 6.31 (新規性 3.8 / 実務影響 7.6 / 信頼性 6.0 / 鮮度 10.0)

### 5. MedErrBench: A Fine-Grained Multilingual Benchmark for Medical Error Detection and Correction with Clinical Expert Annotations
- URL: https://arxiv.org/abs/2602.05692
- Source: cs.CL updates on arXiv.org
- Score: 6.20 (新規性 5.4 / 実務影響 6.2 / 信頼性 7.0 / 鮮度 7.0)

### 6. OpenAI launches a way for enterprises to build and manage AI agents
- URL: https://techcrunch.com/2026/02/05/openai-launches-a-way-for-enterprises-to-build-and-manage-ai-agents/
- Source: TechCrunch
- Score: 6.17 (新規性 5.8 / 実務影響 4.8 / 信頼性 6.0 / 鮮度 10.0)

### 7. ContextBench: A Benchmark for Context Retrieval in Coding Agents
- URL: https://arxiv.org/abs/2602.05892
- Source: cs.LG updates on arXiv.org
- Score: 6.14 (新規性 5.4 / 実務影響 6.0 / 信頼性 7.0 / 鮮度 7.0)

### 8. SAGE: Benchmarking and Improving Retrieval for Deep Research Agents
- URL: https://arxiv.org/abs/2602.05975
- Source: cs.CL updates on arXiv.org
- Score: 6.14 (新規性 5.4 / 実務影響 6.0 / 信頼性 7.0 / 鮮度 7.0)

## Longlist (Top 30)
| Rank | Score | Title | Source | URL |
| :--- | ---: | :--- | :--- | :--- |
| 1 | 6.59 | OpenAI launches new agentic coding model only minutes after Anthropic drops its own | TechCrunch | [link](https://techcrunch.com/2026/02/05/openai-launches-new-agentic-coding-model-only-minutes-after-anthropic-drops-its-own/) |
| 2 | 6.59 | Anthropic releases Opus 4.6 with new ‘agent teams’ | TechCrunch | [link](https://techcrunch.com/2026/02/05/anthropic-releases-opus-4-6-with-new-agent-teams/) |
| 3 | 6.50 | IndustryShapes: An RGB-D Benchmark dataset for 6D object pose estimation of industrial assembly components and tools | cs.RO updates on arXiv.org | [link](https://arxiv.org/abs/2602.05555) |
| 4 | 6.31 | Sapiom raises $15M to help AI agents buy their own tech tools | TechCrunch | [link](https://techcrunch.com/2026/02/05/sapiom-raises-15m-to-help-ai-agents-buy-their-own-tech-tools/) |
| 5 | 6.20 | MedErrBench: A Fine-Grained Multilingual Benchmark for Medical Error Detection and Correction with Clinical Expert Annotations | cs.CL updates on arXiv.org | [link](https://arxiv.org/abs/2602.05692) |
| 6 | 6.17 | OpenAI launches a way for enterprises to build and manage AI agents | TechCrunch | [link](https://techcrunch.com/2026/02/05/openai-launches-a-way-for-enterprises-to-build-and-manage-ai-agents/) |
| 7 | 6.14 | ContextBench: A Benchmark for Context Retrieval in Coding Agents | cs.LG updates on arXiv.org | [link](https://arxiv.org/abs/2602.05892) |
| 8 | 6.14 | SAGE: Benchmarking and Improving Retrieval for Deep Research Agents | cs.CL updates on arXiv.org | [link](https://arxiv.org/abs/2602.05975) |
| 9 | 6.11 | ProOPF: Benchmarking and Improving LLMs for Professional-Grade Power Systems Optimization Modeling | eess.SY updates on arXiv.org | [link](https://arxiv.org/abs/2602.03070) |
| 10 | 6.00 | A Unified Multimodal Framework for Dataset Construction and Model-Based Diagnosis of Ameloblastoma | cs.CL updates on arXiv.org | [link](https://arxiv.org/abs/2602.05515) |
| 11 | 5.96 | M^3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark | cs.AI updates on arXiv.org | [link](https://arxiv.org/abs/2511.17729) |
| 12 | 5.72 | Hamiltonian Benchmark of a Solid-State Spin-Photon Interface for Computation | quant-ph updates on arXiv.org | [link](https://arxiv.org/abs/2602.05637) |
| 13 | 5.72 | A scalability benchmark study of model order reduction techniques for very large, strongly coupled vibroacoustic problems | physics.app-ph updates on arXiv.org | [link](https://arxiv.org/abs/2602.04513) |
| 14 | 5.72 | Benchmarking Affordance Generalization with BusyBox | cs.RO updates on arXiv.org | [link](https://arxiv.org/abs/2602.05441) |
| 15 | 5.72 | Benchmarking Artificial Intelligence Models for Daily Coastal Hypoxia Forecasting | cs.LG updates on arXiv.org | [link](https://arxiv.org/abs/2602.05178) |
| 16 | 5.72 | OpenMAG: A Comprehensive Benchmark for Multimodal-Attributed Graph | cs.LG updates on arXiv.org | [link](https://arxiv.org/abs/2602.05576) |
| 17 | 5.72 | Accelerating Benchmarking of Functional Connectivity Modeling via Structure-aware Core-set Selection | cs.LG updates on arXiv.org | [link](https://arxiv.org/abs/2602.05667) |
| 18 | 5.72 | VRIQ: Benchmarking and Analyzing Visual-Reasoning IQ of VLMs | cs.LG updates on arXiv.org | [link](https://arxiv.org/abs/2602.05382) |
| 19 | 5.72 | GreekMMLU: A Native-Sourced Multitask Benchmark for Evaluating Language Models in Greek | cs.CL updates on arXiv.org | [link](https://arxiv.org/abs/2602.05150) |
| 20 | 5.72 | CASTLE: A Comprehensive Benchmark for Evaluating Student-Tailored Personalized Safety in Large Language Models | cs.CL updates on arXiv.org | [link](https://arxiv.org/abs/2602.05633) |
| 21 | 5.72 | OdysseyArena: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions | cs.CL updates on arXiv.org | [link](https://arxiv.org/abs/2602.05843) |
| 22 | 5.72 | KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs | cs.CL updates on arXiv.org | [link](https://arxiv.org/abs/2602.05929) |
| 23 | 5.72 | Benchmarking Automatic Speech Recognition for Indian Languages in Agricultural Contexts | cs.AI updates on arXiv.org | [link](https://arxiv.org/abs/2602.03868) |
| 24 | 5.72 | Vision Transformers for Zero-Shot Clustering of Animal Images: A Comparative Benchmarking Study | cs.AI updates on arXiv.org | [link](https://arxiv.org/abs/2602.03894) |
| 25 | 5.72 | Med-MMFL: A Multimodal Federated Learning Benchmark in Healthcare | cs.AI updates on arXiv.org | [link](https://arxiv.org/abs/2602.04416) |
| 26 | 5.72 | SLUM-i: Semi-supervised Learning for Urban Mapping of Informal Settlements and Data Quality Benchmarking | cs.AI updates on arXiv.org | [link](https://arxiv.org/abs/2602.04525) |
| 27 | 5.72 | SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization | cs.AI updates on arXiv.org | [link](https://arxiv.org/abs/2602.04811) |
| 28 | 5.68 | ArkTS-CodeSearch: A Open-Source ArkTS Dataset for Code Retrieval | cs.CL updates on arXiv.org | [link](https://arxiv.org/abs/2602.05550) |
| 29 | 5.67 | Learning Soccer Skills for Humanoid Robots: A Progressive Perception-Action Framework | cs.RO updates on arXiv.org | [link](https://arxiv.org/abs/2602.05310) |
| 30 | 5.64 | A Unified Framework for Rethinking Policy Divergence Measures in GRPO | cs.LG updates on arXiv.org | [link](https://arxiv.org/abs/2602.05494) |
